{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitted By: Arhum Ahmed\n",
    "### Roll No: 2020-EE-123\n",
    "### Section: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A Custom Dataset class to load data.\n",
    "    It returns a list of tuple elements, in format (img_array, label).\n",
    "    The output data is in tensor format. \n",
    "'''\n",
    "\n",
    "class CustomDataSet():\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir     = data_dir\n",
    "        self.list_classes = os.listdir(data_dir) # Fetching classes using the folders\n",
    "        self.transform    = transforms.Compose([transforms.ToTensor()])  # Transforms data to torch tensor\n",
    "        self.images       = self.load_images()   # Function to load images\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def load_images(self):\n",
    "        data_set = []\n",
    "        self.list_classes = os.listdir(self.data_dir)    # Defining the classes of Images\n",
    "        for i in self.list_classes:                 \n",
    "            sub_dir   = os.path.join(self.data_dir, i)\n",
    "            sub_class = os.listdir(sub_dir)\n",
    "            for img in sub_class:\n",
    "                img_path  = os.path.join(sub_dir, img)   # Fetching images     \n",
    "                img_array = self.transform(Image.open(img_path)) # Converting images to tensor\n",
    "                data_set.append((img_array, i))\n",
    "        return data_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data using the dataset class\n",
    "\n",
    "path_train      = 'train' \n",
    "path_test       = 'test'\n",
    "path_validation = 'validation'\n",
    "\n",
    "data_set_train      = CustomDataSet(path_train) \n",
    "data_set_test       = CustomDataSet(path_test)\n",
    "data_set_validation = CustomDataSet(path_validation)\n",
    "\n",
    "print('Length of dataset:',len(data_set_train))  # trying len function\n",
    "print('Length of dataset:',len(data_set_test)) \n",
    "print('Length of dataset:',len(data_set_validation))\n",
    "print('Data at index:',data_set_train[3])    # Trying getitem function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A custom DataLoader class to load data into batches\n",
    "    Its features are batch sizes and shuffle mode\n",
    "    It can iterate over the batch using loop\n",
    "    The output is a list containing each batch-list as an element\n",
    "'''\n",
    "\n",
    "class CustomDataLoader():\n",
    "    def __init__(self, dataset, batch_size, shuffle=True, infinite_iter=False):  \n",
    "        self.batch_size    = batch_size\n",
    "        self.dataset       = dataset\n",
    "        self.shuffle       = shuffle\n",
    "        self.infinite_iter = infinite_iter # If true then an infinite loop of n batches is covered\n",
    "        self.step          = 0    \n",
    "    \n",
    "    def __iter__(self):  # Function to iterate using loop\n",
    "        return self\n",
    "    \n",
    "    def __next__(self): # Function to call the next batch \n",
    "        if self.step >= len(self.dataset) and not(self.infinite_iter): # It is used to stop the iteration of loop when limit reached \n",
    "                raise StopIteration          \n",
    "                         \n",
    "        batch      = []\n",
    "        label_out  = []\n",
    "        sample_out = []\n",
    "        batch_out  = []\n",
    "\n",
    "        if self.shuffle:\n",
    "            indices = torch.randperm(len(self.dataset)) # Generate random indices for shuffling\n",
    "            temp = []\n",
    "            for i in indices:                # Iterate on those random indices\n",
    "                temp.append(self.dataset[i]) # Add the corresponding elements to a list\n",
    "            self.dataset = temp              # Saving the shuffled list \n",
    "            \n",
    "        for j in range(0, len(self.dataset), self.batch_size): # Makes pointers for batches \n",
    "            if self.step >= len(self.dataset): # Break if limit reached\n",
    "                if (self.infinite_iter): # if infinite_iter True then restart the counter\n",
    "                    self.step = 0\n",
    "                else:\n",
    "                    break\n",
    "            for _ in range(0+j, j+self.batch_size): # Iterate over the batch pointers\n",
    "                if self.step >= len(self.dataset):  # Break if limit reached\n",
    "                    if (self.infinite_iter):  # if infinite_iter True then restart the counter\n",
    "                        self.step = 0\n",
    "                    else:\n",
    "                        break\n",
    "                sample, lbl = self.dataset[self.step]\n",
    "                sample_out.append(sample)\n",
    "                label_out.append(lbl)\n",
    "                self.step += 1\n",
    "\n",
    "            batch_out.append(tuple(sample_out))\n",
    "            batch_out.append(tuple(label_out))\n",
    "            batch.append(batch_out)\n",
    "            batch_out  = []\n",
    "            label_out  = []\n",
    "            sample_out = []\n",
    "\n",
    "        return batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the data extracted to create batches using custom dataloader\n",
    "\n",
    "# Batches are retrived, when infinite_inter=False\n",
    "train_data = CustomDataLoader(data_set_train, batch_size=32, shuffle=True, infinite_iter=False)\n",
    "\n",
    "for batch in train_data:\n",
    "    print(batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
